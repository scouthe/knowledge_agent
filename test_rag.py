import os
import chromadb
from chromadb.utils import embedding_functions
import httpx
import json
import re
import time
os.environ["CHROMA_ANONYMIZED_TELEMETRY"] = "False"

import chromadb
# å¼•å…¥é…ç½®
from config import (
    CHROMA_DB_PATH, 
    CHROMA_COLLECTION_NAME, 
    EMBEDDING_API_URL, 
    EMBEDDING_MODEL_NAME,
    LLM_API_URL,
    LLM_MODEL
)

# === 1. å®šä¹‰ä¸€ä¸ªç®€å•çš„ä¼šè¯çŠ¶æ€ç±» ===
class ConversationSession:
    def __init__(self):
        self.history_doc_ids = []  # å­˜ä¸Šä¸€è½®å‘½ä¸­çš„æ–‡ç«  ID (Parent ID)
        self.last_topic = ""       # å­˜ä¸Šä¸€è½®çš„ä¸»é¢˜ï¼ˆå¯é€‰ï¼‰

    def update(self, doc_ids, query):
        """æ›´æ–°é”šç‚¹"""
        # åªä¿ç•™å”¯ä¸€çš„æ–‡ç«  ID
        self.history_doc_ids = list(set(doc_ids))
        self.last_topic = query

    def clear(self):
        self.history_doc_ids = []
        self.last_topic = ""
        print("ğŸ§¹ ä¼šè¯å·²é‡ç½®")

# åˆå§‹åŒ–å…¨å±€ä¼šè¯
session = ConversationSession()

def detect_intent_with_llm(query, last_topic):
    """
    ä½¿ç”¨ LLM åˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼šæ˜¯ã€å¼€å¯æ–°è¯é¢˜ã€‘è¿˜æ˜¯ã€è¿½é—®ä¸Šä¸€è½®ã€‘
    """
    # å¦‚æœæ²¡æœ‰ä¸Šä¸€è½®è¯é¢˜ï¼Œè‚¯å®šæ˜¯æ–°è¯é¢˜
    if not last_topic:
        return False
        
    print(f"ğŸ¤” æ­£åœ¨åˆ†ææ„å›¾... (ä¸Šè½®: {last_topic[:10]}...)")

    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ„å›¾åˆ†ç±»å™¨ã€‚
    ä»»åŠ¡ï¼šåˆ¤æ–­ã€å½“å‰é—®é¢˜ã€‘æ˜¯å¦æ˜¯é’ˆå¯¹ã€ä¸Šè½®è¯é¢˜ã€‘çš„è¿½é—®æˆ–æŒ‡ä»£ã€‚
    
    è¾“å‡ºè§„åˆ™ï¼š
    1. å¦‚æœæ˜¯è¿½é—®/æŒ‡ä»£/æ‰¿æ¥ï¼Œåªè¾“å‡ºå•è¯ï¼šTRUE
    2. å¦‚æœæ˜¯å…¨æ–°çš„æ— å…³è¯é¢˜ï¼Œåªè¾“å‡ºå•è¯ï¼šFALSE
    
    ç¤ºä¾‹ï¼š
    ä¸Šè½®ï¼šDeepSeekçš„ä¼˜ç‚¹
    å½“å‰ï¼šå®ƒæ€ä¹ˆæ”¶è´¹ï¼Ÿ -> TRUE
    
    ä¸Šè½®ï¼šDeepSeekçš„ä¼˜ç‚¹
    å½“å‰ï¼šä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ -> FALSE
    
    ä¸Šè½®ï¼šDeepSeekçš„ä¼˜ç‚¹
    å½“å‰ï¼šè®²è®²Qwenæ¨¡å‹ -> FALSE (è¿™æ˜¯æ–°å®ä½“)
    """
    
    user_prompt = f"ä¸Šè½®è¯é¢˜ï¼š{last_topic}\nå½“å‰é—®é¢˜ï¼š{query}"

    payload = {
        "model": LLM_MODEL,
        "temperature": 0.1, # åˆ†ç±»ä»»åŠ¡æ¸©åº¦è¦ä½
        "max_tokens": 10,   # åªéœ€è¦ä¸€ä¸ªè¯
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }

    try:
        resp = httpx.post(LLM_API_URL, json=payload, timeout=10)
        result = resp.json()['choices'][0]['message']['content'].strip().upper()
        
        # åªè¦ LLM è¯´æ˜¯ TRUEï¼Œå°±æ˜¯é”šå®šæ¨¡å¼
        is_follow_up = "TRUE" in result
        print(f"ğŸ‘‰ æ„å›¾åˆ¤å®šç»“æœ: {'âš“ï¸ è¿½é—® (é”šå®š)' if is_follow_up else 'ğŸŒ æ–°è¯é¢˜ (å…¨å±€)'}")
        return is_follow_up
        
    except Exception as e:
        print(f"âš ï¸ æ„å›¾è¯†åˆ«å¤±è´¥ï¼Œé™çº§ä¸ºå…¨å±€æœç´¢: {e}")
        return False

def is_follow_up_question(query):
    """
    ç®€å•å¯å‘å¼è§„åˆ™ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯è¿½é—®/æŒ‡ä»£
    è§„åˆ™ï¼šé•¿åº¦çŸ­ï¼Œæˆ–åŒ…å«ä»£è¯
    """
    if len(query) < 10: return True
    triggers = ["ä»–", "å®ƒ", "è¿™", "é‚£", "å…¶", "æ€ä¹ˆç”¨", "æ˜¯è°", "ç»§ç»­", "æ·±å…¥"]
    return any(t in query for t in triggers)
# === [æ–°å¢] åˆ—ä¸¾æ¨¡å¼å‡½æ•° ===
def handle_list_request(collection, query_text):
    """
    å¤„ç†ç±»ä¼¼â€œæœ‰å“ªäº›æ–‡ç« â€ã€â€œåˆ—å‡ºæ ‡é¢˜â€çš„è¯·æ±‚
    ç›´æ¥æŸ¥å…ƒæ•°æ®ï¼Œä¸èµ°å‘é‡æœç´¢
    """
    # ç®€å•çš„å…³é”®è¯åˆ¤æ–­ï¼Œå®é™…å¯ä»¥ç”¨ LLM åˆ¤æ–­
    triggers = ["æœ‰å“ªäº›", "æœ‰ä»€ä¹ˆ", "åˆ—ä¸€ä¸‹", "åˆ—å‡º", "æ¸…å•", "å¤šå°‘ç¯‡", "å‡ ä¸ªæ–‡ç« "]
    if not any(t in query_text for t in triggers) or "æ–‡ç« " not in query_text:
        return False

    print("ğŸ“‹ æ£€æµ‹åˆ°ã€åˆ—ä¸¾/ç»Ÿè®¡ã€‘æ„å›¾ï¼Œæ­£åœ¨æŸ¥è¯¢å…ƒæ•°æ®...")
    
    # è·å–ä»Šå¤©æ—¥æœŸçš„å‰ç¼€ (ä½ çš„ metadata created_at æ ¼å¼æ˜¯ YYYY-MM-DD HH:MM:SS)
    today_str = time.strftime("%Y-%m-%d")
    
    # ç›´æ¥ä» Chroma è·å–å…ƒæ•°æ® (limit è®¾å¤§ä¸€ç‚¹ï¼Œæ¯”å¦‚ 100)
    # è¿™æ˜¯ä¸€ä¸ªæ•°æ®åº“æŸ¥è¯¢æ“ä½œï¼Œä¸æ˜¯å‘é‡æœç´¢
    results = collection.get(
        include=["metadatas"],
        limit=100 
    )
    
    metadatas = results['metadatas']
    
    # è¿‡æ»¤å’Œå»é‡
    unique_titles = set()
    today_count = 0
    
    for meta in metadatas:
        title = meta.get('title', 'æ— æ ‡é¢˜')
        created_at = meta.get('created_at', '')
        
        # å°†æ ‡é¢˜åŠ å…¥é›†åˆ (å»é‡)
        unique_titles.add(title)
        
        # ç»Ÿè®¡ä»Šå¤©çš„ (å¯é€‰)
        if today_str in created_at:
            today_count += 1
            
    # ç›´æ¥æ„é€ å›ç­”ï¼Œä¸éœ€è¦ LLM æ€è€ƒ (æˆ–è€…ä¹Ÿå¯ä»¥å–‚ç»™ LLM æ¶¦è‰²)
    print("-" * 50)
    print("ğŸ¤– ç³»ç»Ÿç›´å‡ºç»“æœ:")
    print(f"\nğŸ“š çŸ¥è¯†åº“å½“å‰å·²æ”¶å½• {len(unique_titles)} ç¯‡æ–‡ç« ï¼ˆåˆ‡ç‰‡æ€»æ•°: {len(metadatas)}ï¼‰ï¼š\n")
    
    for i, title in enumerate(unique_titles, 1):
        print(f"{i}. ã€Š{title}ã€‹")
        
    print(f"\n(æ³¨: ä»¥ä¸Šæ˜¯å…¨é‡åˆ—è¡¨ï¼Œä»Šæ—¥æ›´æ–°å¯èƒ½åŒ…å«åœ¨å†…)")
    return True

def list_articles(filter_today=True):
    """
    å¿«æ·æŒ‡ä»¤ï¼šåˆ—å‡ºæ–‡ç« 
    filter_today=True: åªåˆ—å‡ºä»Šå¤©çš„
    filter_today=False: åˆ—å‡ºæ‰€æœ‰
    """
    print("ğŸ“‹ æ­£åœ¨è¯»å–çŸ¥è¯†åº“ç›®å½•...")
    
    # ä¸´æ—¶è¿æ¥æ•°æ®åº“
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    # è·å–é›†åˆ (ä¸éœ€è¦ embedding functionï¼Œå› ä¸ºåªæŸ¥å…ƒæ•°æ®)
    collection = client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)
    
    # è·å–æ‰€æœ‰å…ƒæ•°æ®
    results = collection.get(include=["metadatas"])
    metadatas = results['metadatas']
    
    if not metadatas:
        print("ğŸ“­ çŸ¥è¯†åº“æ˜¯ç©ºçš„ã€‚")
        return

    today_str = time.strftime("%Y-%m-%d")
    unique_titles = set()
    today_count = 0
    
    # ç­›é€‰é€»è¾‘
    for meta in metadatas:
        title = meta.get('title', 'æ— æ ‡é¢˜')
        created_at = meta.get('created_at', '')
        
        # å¦‚æœåªçœ‹ä»Šå¤©ï¼Œä¸”æ—¥æœŸä¸åŒ¹é…ï¼Œè·³è¿‡
        if filter_today and today_str not in created_at:
            continue
            
        unique_titles.add(title)

    # æ‰“å°ç»“æœ
    print("-" * 50)
    title_prefix = f"ğŸ“… ã€{today_str}ã€‘" if filter_today else "ğŸ“š ã€å…¨é‡ã€‘"
    
    if not unique_titles:
        print(f"{title_prefix} æš‚æ— æ”¶å½•æ–‡ç« ã€‚")
    else:
        print(f"{title_prefix} å·²æ”¶å½• {len(unique_titles)} ç¯‡æ–‡ç« ï¼š\n")
        for i, title in enumerate(unique_titles, 1):
            print(f"{i}. ã€Š{title}ã€‹")
            
    print("-" * 50)
def test_rag(query_text):
    global session
    
    # æ‰‹åŠ¨é‡ç½®æŒ‡ä»¤
    if query_text.strip() == "/new":
        session.clear()
        return

    print(f"\nğŸ” æ­£åœ¨æé—®: ã€{query_text}ã€‘")
    
    # 1. è¿æ¥å‘é‡åº“
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    emb_fn = embedding_functions.OpenAIEmbeddingFunction(
        api_key="lm-studio",
        api_base=EMBEDDING_API_URL,
        model_name=EMBEDDING_MODEL_NAME
    )
    collection = client.get_collection(name=CHROMA_COLLECTION_NAME, embedding_function=emb_fn)
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    collection = client.get_collection(name=CHROMA_COLLECTION_NAME, embedding_function=emb_fn)
    if handle_list_request(collection, query_text):
        return
    # === 2. å…³é”®é€»è¾‘ï¼šAI å†³å®šæ£€ç´¢ç­–ç•¥ ===
    search_kwargs = {
        "query_texts": [query_text],
        "n_results": 5
    }
    
    is_anchored = False
    
    # [ä¿®æ”¹ç‚¹]ï¼šä¸å†ç”¨ len() æˆ–å…³é”®è¯ï¼Œç›´æ¥é—® LLM
    # åªæœ‰å½“ session é‡Œæœ‰ä¸œè¥¿ï¼Œæ‰éœ€è¦åˆ¤æ–­æ˜¯ä¸æ˜¯è¿½é—®
    if session.history_doc_ids:
        # ä¼ å…¥ï¼šå½“å‰é—®é¢˜ + ä¸Šä¸€è½®çš„é—®é¢˜(ä½œä¸ºè¯é¢˜èƒŒæ™¯)
        if detect_intent_with_llm(query_text, session.last_topic):
            print(f"âš“ï¸ è§¦å‘é”šå®šæ¨¡å¼ï¼é”å®šèŒƒå›´: {len(session.history_doc_ids)} ç¯‡æ–‡ç« ")
            search_kwargs["where"] = {"parent_id": {"$in": session.history_doc_ids}}
            is_anchored = True
        else:
            print("ğŸŒ åˆ¤å®šä¸ºæ–°è¯é¢˜ï¼Œè¿›è¡Œå…¨å±€æ£€ç´¢")
            session.clear() # æ¸…ç†æ—§çŠ¶æ€
    else:
        print("ğŸŒ å…¨å±€æ£€ç´¢æ¨¡å¼ (æ— å†å²)")

    # æ‰§è¡Œæ£€ç´¢
    results = collection.query(**search_kwargs)

    # ç»“æœè§£åŒ…
    documents = results['documents'][0]
    metadatas = results['metadatas'][0]
    distances = results['distances'][0]
    ids = results['ids'][0]

    if not documents:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
        if is_anchored:
            print("ğŸ”„ å°è¯•åˆ‡æ¢å›å…¨å±€æœç´¢...")
            session.clear() # æ¸…é™¤ä¸Šä¸‹æ–‡é‡è¯•
            test_rag(query_text) # é€’å½’è°ƒç”¨ä¸€æ¬¡
        return

    print(f"âœ… æ£€ç´¢åˆ° {len(documents)} æ¡ç›¸å…³åˆ‡ç‰‡:\n")
    
    # æ”¶é›†è¿™æ¬¡å‘½ä¸­çš„ parent_idï¼Œç”¨äºæ›´æ–°ä¸‹ä¸€è½®é”šç‚¹
    current_doc_ids = []
    context_parts = []
    
    for i, doc in enumerate(documents):
        # ä½ çš„ metadata é‡Œåº”è¯¥æœ‰ parent_id (å¯¹åº”æ•´ç¯‡æ–‡ç« çš„ doc_id)
        # å¦‚æœæ²¡æœ‰ parent_idï¼Œç”¨ doc_id ä¹Ÿè¡Œï¼Œå–å†³äºä½  storage.py æ€ä¹ˆå­˜çš„
        # å‡è®¾ä½ æ˜¨å¤©çš„ä»£ç å­˜çš„æ˜¯ parent_id
        p_id = metadatas[i].get('parent_id') 
        if p_id: current_doc_ids.append(p_id)
        
        chunk_id_short = ids[i].split('_')[-1]
        title = metadatas[i].get('title', 'æœªçŸ¥')
        dist = distances[i]
        
        print(f"ğŸ§© [ID: {chunk_id_short}] (è·ç¦»: {dist:.4f}) - {title}")
        context_parts.append(f"ã€å‚è€ƒç‰‡æ®µ {i+1} (ID: {chunk_id_short})ã€‘\n{doc}")

    # === 3. æ›´æ–°ä¼šè¯çŠ¶æ€ ===
    # åªæœ‰åœ¨éé”šå®šæ¨¡å¼ï¼ˆæ–°è¯é¢˜ï¼‰ä¸‹ï¼Œæ‰å¤§å¹…æ›´æ–° doc_ids
    # å¦‚æœæ˜¯é”šå®šæ¨¡å¼ï¼Œæˆ‘ä»¬ä¿æŒèŒƒå›´ï¼Œæˆ–è€…å–äº¤é›†ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºè¦†ç›–ï¼‰
    if not is_anchored:
        session.update(current_doc_ids, query_text)
    
    # 4. ç”Ÿæˆ (Generate)
    print("-" * 50)
    print("ğŸ¤– æ­£åœ¨æ€è€ƒ...")
    
    context_str = "\n\n".join(context_parts)
    
    # === [ä¼˜åŒ–ç‰ˆ] System Prompt ===
    
    # åŸºç¡€äººè®¾
    base_prompt = """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®æ£€ç´¢åˆ°çš„ç‰‡æ®µå›ç­”ç”¨æˆ·é—®é¢˜ã€‚
    """
    
    # é”šå®šæ¨¡å¼ä¸‹çš„ç‰¹æ®ŠæŒ‡ä»¤
    if is_anchored:
        base_prompt += """
        èƒŒæ™¯ï¼šç”¨æˆ·æ­£åœ¨é’ˆå¯¹ä¸Šæ–‡è¿›è¡Œæ·±å…¥è¿½é—®ã€‚
        ä»»åŠ¡ï¼šè¯·ç»¼åˆã€å‚è€ƒç‰‡æ®µã€‘ä¸­çš„ä¿¡æ¯ï¼Œç”¨é€šé¡ºã€é€»è¾‘æ¸…æ™°çš„è¯­è¨€å›ç­”ã€‚
        
        âš ï¸ å…³é”®ä¿®æ­£è¦æ±‚ï¼š
        1. **äººç§°è½¬æ¢**ï¼šå¦‚æœåŸæ–‡ä½¿ç”¨ç¬¬ä¸€äººç§°ï¼ˆâ€œæˆ‘â€ã€â€œç¬”è€…â€ï¼‰ï¼Œè¯·æ”¹ä¸ºç¬¬ä¸‰äººç§°æè¿°ï¼ˆå¦‚â€œä½œè€…æåˆ°â€ã€â€œæ–‡ä¸­æŒ‡å‡ºâ€ï¼‰ï¼Œä¸è¦è®©ç”¨æˆ·è§‰å¾—æ˜¯ä½ åœ¨è‡ªè¿°ã€‚
        2. **å»é™¤å£è¯­åºŸè¯**ï¼šå»æ‰åŸæ–‡ä¸­ç±»ä¼¼â€œå¦‚ä¸‹å›¾æ‰€ç¤ºâ€ã€â€œå¤§å®¶çœ‹è¿™é‡Œâ€ç­‰æ— æ³•å±•ç¤ºçš„è§†è§‰å¼•å¯¼è¯ã€‚
        3. **æ€»ç»“è€Œéå¤åˆ¶**ï¼šä¸è¦æœºæ¢°æŠ„å†™åŸæ–‡ï¼Œè¯·æå–æ ¸å¿ƒé€»è¾‘è¿›è¡Œæ¦‚æ‹¬ã€‚
        """

    system_prompt = f"""
    {base_prompt}
    
    ã€å‚è€ƒç‰‡æ®µã€‘ï¼š
    {context_str}
    
    ã€å›ç­”è§„åˆ™ã€‘ï¼š
    1. å¿…é¡»åŸºäºäº‹å®ï¼Œä¸¥è°¨å‡†ç¡®ã€‚
    2. å¼•ç”¨æ ‡æ³¨ï¼šåœ¨æ ¸å¿ƒè§‚ç‚¹çš„å¥å°¾åŠ ä¸Šæ¥æº IDï¼Œå¦‚ [ID: xxx]ã€‚
    3. è¯­æ°”è¦è‡ªç„¶ã€å®¢è§‚ï¼Œåƒä¸€ä¸ªä¸“ä¸šçš„åˆ†æå¸ˆåœ¨ä»‹ç»å†…å®¹ï¼Œè€Œä¸æ˜¯å¤è¯»æœºã€‚
    """
    
    # user_prompt ä¿æŒç®€å•
    user_prompt = f"{query_text}"

    payload = {
        "model": LLM_MODEL,
        "temperature": 0.3, 
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    }

    try:
        resp = httpx.post(LLM_API_URL, json=payload, timeout=60)
        ai_answer = resp.json()['choices'][0]['message']['content']
        print(f"\nğŸ’¡ AI å›ç­”:\n{ai_answer}")
    except Exception as e:
        print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ’¡ æç¤º:")
    print("  - è¾“å…¥ 'q' é€€å‡º")
    print("  - è¾“å…¥ 'l' æŸ¥çœ‹ä»Šå¤©æ–‡ç«  (List Today)")
    print("  - è¾“å…¥ 'all' æŸ¥çœ‹æ‰€æœ‰æ–‡ç« ")
    print("  - è¾“å…¥ '/new' é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡")
    
    while True:
        # è¿™é‡Œçš„ input æç¤ºç¬¦å¯ä»¥ç®€åŒ–ä¸€ç‚¹
        q = input("\nğŸ™‹ è¯·è¾“å…¥ (q/l/é—®é¢˜): ").strip()
        
        if not q: continue
        
        # === å¿«æ·é”®ç›‘å¬ ===
        if q.lower() == 'q': 
            break
            
        elif q.lower() == 'l':
            # è§¦å‘ä»Šæ—¥åˆ—è¡¨
            list_articles(filter_today=True)
            continue # è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œä¸è¿›å…¥ test_rag
            
        elif q.lower() == 'all':
            # è§¦å‘å…¨é‡åˆ—è¡¨
            list_articles(filter_today=False)
            continue
            
        # === æ­£å¸¸æé—® ===
        test_rag(q)